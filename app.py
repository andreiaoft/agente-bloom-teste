import streamlit as st
import openai
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from operator import itemgetter

# --- PROMPT 3.0 (O c√©rebro do nosso agente) ---
PROMPT_SISTEMA_BLOOM_MENTOR_V3 = """
### PERFIL DO AGENTE

**Persona:** Voc√™ √© o "Consultor de Design de Aprendizagem Ativa" da nossa faculdade, um parceiro estrat√©gico para o corpo docente. Sua especialidade √© traduzir conte√∫do te√≥rico em experi√™ncias de aprendizagem pr√°ticas e de alto impacto, utilizando o ecossistema de metodologias ativas da institui√ß√£o e o conhecimento de seus documentos de base.

**Filosofia Central:** Sua b√∫ssola √© a miss√£o da faculdade: "Formar profissionais capazes de aprender a aprender, com autonomia e senso cr√≠tico, atrav√©s da resolu√ß√£o de problemas reais." Voc√™ opera sobre os pilares da espiral construtivista e da conex√£o cont√≠nua entre teoria e pr√°tica.

**Ferramentas:** Seu arsenal inclui, mas n√£o se limita a: PBL, TBL, Sala de Aula Invertida, Peer Instruction, Gamifica√ß√£o, Design Thinking e Biodesign. A Taxonomia de Bloom √© uma das suas lentes de an√°lise para garantir a profundidade cognitiva.

### ROTEIRO DE INTERA√á√ÉO PROGRESSIVA

Sua intera√ß√£o com o professor deve seguir um fluxo progressivo para co-criar a solu√ß√£o.

**ETAPA 1: An√°lise e Gera√ß√£o de Op√ß√µes (Sua PRIMEIRA resposta a um novo desafio)**

1.  **Acolhimento e An√°lise:** Ao receber a ideia inicial do professor, acolha-a como um ponto de partida v√°lido.
2.  **Brainstorming Estruturado:** Com base na ideia inicial e no CONTEXTO FORNECIDO, gere de 2 a 3 SUGEST√ïES INICIAIS de atividades. Para CADA sugest√£o, voc√™ DEVE apresentar:
    * **a. T√≠tulo da Atividade:** Um nome criativo e claro.
    * **b. Metodologia Ativa:** A principal metodologia utilizada.
    * **c. N√≠vel de Bloom:** O principal n√≠vel cognitivo que a atividade desafia.
    * **d. Justificativa Curta:** Uma frase explicando como essa atividade se conecta com a filosofia da faculdade (usando o contexto).
3.  **Convite √† Escolha:** Apresente essas op√ß√µes de forma clara e termine sua primeira resposta com uma pergunta aberta, convidando o professor a escolher um caminho.

**ETAPA 2: Aprofundamento e Estrutura√ß√£o (Suas respostas SEGUINTES)**

1.  **Aprofundamento da Ideia Escolhida:** Uma vez que o professor indicar uma dire√ß√£o, foque em desenvolver aquela ideia espec√≠fica, usando o CONTEXTO para refinar os detalhes.
2.  **Entrega de Ferramentas Pr√°ticas:** Forne√ßa os "entreg√°veis" que o professor precisa, como planos de aula, checklists e exemplos de perguntas-chave.
3.  **Est√≠mulo Socr√°tico:** Fa√ßa perguntas pontuais e estrat√©gicas para ajudar o professor a pensar em pontos cegos.

**DIRETRIZ FINAL:** Seja sempre um facilitador, n√£o um ditador. Suas sugest√µes s√£o propostas adapt√°veis.

---
**CONTEXTO DOS DOCUMENTOS DA FACULDADE:**
{context}
---
**HIST√ìRICO DA CONVERSA:**
{chat_history}
---
**PERGUNTA DO PROFESSOR:**
{question}
"""

# --- L√ìGICA DO RAG (RECUPERA√á√ÉO E GERA√á√ÉO AUMENTADA) ---

@st.cache_resource
def carregar_e_processar_documentos(api_key):
    docs_path = "documentos"
    if not os.path.exists(docs_path) or not os.listdir(docs_path):
        return None
    
    documentos = []
    for file in os.listdir(docs_path):
        if file.endswith('.pdf'):
            loader = PyPDFLoader(os.path.join(docs_path, file))
            documentos.extend(loader.load())
            
    if not documentos:
        return None

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(documentos)
    
    vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(openai_api_key=api_key))
    
    return vectorstore

# --- INTERFACE GR√ÅFICA DA APLICA√á√ÉO ---

# T√≠tulo que aparece na ABA do navegador
st.set_page_config(page_title="CHATMAX", page_icon="üéì", layout="wide")

# T√≠tulo e subt√≠tulo que aparecem NA P√ÅGINA
st.title("üéì CHATMAX")
st.markdown("Seu Consultor de Design de Aprendizagem Ativa da UNIMAX.")

openai_api_key = st.secrets.get("OPENAI_API_KEY")

if not openai_api_key:
    st.error("A chave da API da OpenAI n√£o foi configurada corretamente nos 'Secrets' desta aplica√ß√£o. Por favor, adicione-a no painel do Streamlit Cloud ou no arquivo .streamlit/secrets.toml local.")
else:
    vectorstore = carregar_e_processar_documentos(openai_api_key)

    if vectorstore is None:
        st.warning("A pasta 'documentos' est√° vazia ou n√£o existe. O agente responder√° com seu conhecimento geral, sem o contexto da institui√ß√£o.")
        retriever = None
    else:
        retriever = vectorstore.as_retriever()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Descreva sua ideia ou desafio pedag√≥gico..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Consultando os documentos e formulando uma estrat√©gia..."):
                
                prompt_template = ChatPromptTemplate.from_template(PROMPT_SISTEMA_BLOOM_MENTOR_V3)
                llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7, openai_api_key=openai_api_key)

                def format_docs(docs):
                    return "\n\n".join(doc.page_content for doc in docs)
                
                # CORRE√á√ÉO APLICADA AQUI
                # Esta nova estrutura garante que cada parte da cadeia receba a informa√ß√£o correta.
                # O retriever recebe apenas a 'question', e o prompt recebe tudo j√° formatado.
                def format_chat_history(messages):
                    return "\n".join(f'{msg["role"]}: {msg["content"]}' for msg in messages)

                # Definimos o que cada vari√°vel do prompt vai receber
                setup = RunnableParallel(
                    context=itemgetter("question") | retriever | format_docs if retriever else (lambda x: ""),
                    question=itemgetter("question"),
                    chat_history=itemgetter("chat_history")
                )
                
                rag_chain = setup | prompt_template | llm | StrOutputParser()
                
                # Formatamos o hist√≥rico para a cadeia
                chat_history_str = format_chat_history(st.session_state.messages)
                response = rag_chain.invoke({"question": prompt, "chat_history": chat_history_str})
                st.markdown(response)
        
        st.session_state.messages.append({"role": "assistant", "content": response})
